{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming and Classification:\n",
    "## 3. Simple similarity of texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @author Krzysztof Agieńczuk\n",
    "This notebook is available under the beerware license for educational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections_extended import bag\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. (*) For a given bitstring b list all bitstrings b’, such that the Hamming distance between b and b’ is equal 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000111111\n",
      "010000111111\n",
      "001000111111\n",
      "000100111111\n",
      "000010111111\n",
      "000001111111\n",
      "000000011111\n",
      "000000101111\n",
      "000000110111\n",
      "000000111011\n",
      "000000111101\n",
      "000000111110\n"
     ]
    }
   ],
   "source": [
    "b = \"000000111111\"\n",
    "def weirdHamming(bitstring):\n",
    "    index=0\n",
    "    for char in bitstring:\n",
    "        if char == '1': print(bitstring[:index] + \"0\" +bitstring[index+1:])\n",
    "        else: print(bitstring[:index] + \"1\" +bitstring[index+1:])\n",
    "        index+=1\n",
    "        \n",
    "weirdHamming(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. (*) Construct a function that returns a Jaccard similarity for two sets. Beware that this function needs to check if at least one of the sets is nonempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "def jaccardSimilaritySets(element1, element2):\n",
    "    if element2 == []:\n",
    "        return \"empty\"\n",
    "    intersection = set(element1).intersection(set(element2))\n",
    "    union = set(element1).union(set(element2))\n",
    "    return float(len(intersection)/len(union))\n",
    "\n",
    "print(jaccardSimilaritySets([1,2,3,4,5],[3,4,5,6,7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. (*) Construct a function that computes Jaccard similarity for two strings treated as bags of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def jaccardSimilarityBags(element1, element2):\n",
    "    if element2 == []:\n",
    "        return \"empty\"\n",
    "    intersection = bag(element1)&(bag(element2))\n",
    "    union = bag(element1)|(bag(element2))\n",
    "    return float(len(intersection)/len(union))\n",
    "\n",
    "print(jaccardSimilarityBags([1,1,1,2],[1,1,2,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. (**) (use NLTK) List all words in text1 with edit distance from the word dog smaller than 4. Hint: you can safely reject all long words without computations (why?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1Set = set(text1)\n",
    "wordsToConsider = []\n",
    "for word in text1Set:\n",
    "    if len(word)<6:\n",
    "        wordsToConsider.append(word)\n",
    "        \n",
    "#[print(word) for word in wordsToConsider if nltk.edit_distance(word, \"dog\")<4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. (**) (use NLTK) Let text1 - text9 be bags of words. Compute similarity between all pairs of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38013527140025105\n",
      "0.21735487174712537\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    number = i+1\n",
    "    for ii in range(9):\n",
    "        number2 = ii+1\n",
    "        #print(eval(\"text\" + str(number)))\n",
    "        #print(eval(\"text\" + str(number2)))\n",
    "        #print(jaccardSimilarityBags(eval(\"text\" + str(number)),eval(\"text\" + str(number2))))\n",
    "print(jaccardSimilarityBags(text1, text2))\n",
    "print(jaccardSimilaritySets(text1,text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. (**) (use NLTK) Let us consider a metric space (S; d), where S is the set of words from text1 and d is the Hamming distance. Find diameter of (S; d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5526\n",
      "74.43799996376038\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# find biggest value of Hamming distance?\n",
    "def checkHamming(word1, word2):\n",
    "    return sum(letter1 != letter2 for letter1, letter2 in zip(word1, word2))\n",
    "\n",
    "\n",
    "import time\n",
    "text1Set = set(text1)\n",
    "diameter = 0\n",
    "#Can you do it faster?\n",
    "start = time.time()    \n",
    "preparedData = [word for word in text1Set if len(word) > 8]\n",
    "for word1 in preparedData:\n",
    "    for word2 in preparedData:\n",
    "        hammingValue = checkHamming(word1,word2)\n",
    "        if hammingValue > diameter:\n",
    "            diameter = hammingValue\n",
    "end = time.time() - start\n",
    "\n",
    "print(len(preparedData))\n",
    "print(end)\n",
    "print(diameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. (***) (use NLTK) Construct a dictionary that assigns each pair of consecutive words in text1 the Jaccard similarity between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevWord=\"test\"\n",
    "for word in text1:\n",
    "    if len(word)>2:\n",
    "        #print(jaccardSimilaritySets(word.lower(),prevWord.lower()))\n",
    "        prevWord = word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. (***) (use NLTK). For two words v and w, let relative edit distance be the Levensthein distance between v and w divided by the sum of lengths v and w. Find two different words in text2 with minimal relative edit distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\"\"\"\n",
    "Skip comparing the same words\n",
    "Return first occurence of rel edit distance = 1\n",
    "\"\"\"\n",
    "def relEditDist():\n",
    "    minimal = sys.float_info.max\n",
    "    len(set(text2))\n",
    "    for word1 in set(text2):\n",
    "        for word2 in set(text2):\n",
    "            if word1 != word2: \n",
    "                dist = (nltk.edit_distance(word1, word2))/(len(word1)+len(word2))\n",
    "                if dist < minimal:\n",
    "                    minimal = dist\n",
    "    return minimal\n",
    "                \n",
    "relEditDist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. (****) For a given bitstring b and a natural number n list all bitstrings b’, such that the Hamming distance between b and b’ is equal n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0110', '0011', '0011', '0110', '1001', '1001', '1100', '1100', '0011', '0011', '0110', '0110', '1001', '1100', '1100', '1001']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def checkHamming(word1, word2):\n",
    "    return sum(letter1 != letter2 for letter1, letter2 in zip(word1, word2))\n",
    "\n",
    "def makeHammingPermutations(bitstring, n):\n",
    "    retVal = []\n",
    "    allPermutations = [''.join(perm) for perm in itertools.permutations(bitstring)]\n",
    "    retVal = [permutation for permutation in allPermutations if checkHamming(permutation, bitstring) == n]\n",
    "    return retVal\n",
    "\n",
    "print(makeHammingPermutations(\"0101\", 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. (***) Construct a function that for a given string and a natural number k returns a set of all its k-shingles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'his', 'is ', 's i', ' is', 'is ', 's m', ' my', 'my ', 'y w', ' wo', 'wor', 'ord']\n"
     ]
    }
   ],
   "source": [
    "def shingle(word,k):\n",
    "    return [word[i: i+k] for i in range(len(word) - k + 1)]\n",
    "\n",
    "def shingleWord(word, k):\n",
    "    \"\"\"\n",
    "    is this what was to be done? If so, then maybe later\n",
    "    \"\"\"\n",
    "\n",
    "print(shingle(\"this is my word\",3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
